# llm_server_fast
Load a LLM into memory, then send a request via HTTP. This avoids having to load the LLM into memory every time you get a new prompt. 
